{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomasRoa/Integracion-de-datos-2025/blob/main/Thomas_Roa__Reto_integraci%C3%B3n_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn scikit-learn-extra openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9GL8XPaYIBV",
        "outputId": "05728469-527b-454f-eada-83e4f707389c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scikit-learn-extra\n",
            "  Using cached scikit_learn_extra-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Using cached scikit_learn_extra-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Installing collected packages: scikit-learn, scikit-learn-extra\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.6.1 scikit-learn-extra-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scikit-learn scikit-learn-extra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaPvLOeFazaO",
        "outputId": "236c1c3d-a6a3-4b4d-91b5-698b07da1f0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Found existing installation: scikit-learn-extra 0.3.0\n",
            "Uninstalling scikit-learn-extra-0.3.0:\n",
            "  Successfully uninstalled scikit-learn-extra-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy==1.23.5\n",
        "\n",
        "!pip install --upgrade --force-reinstall scikit-learn==1.2.2 scikit-learn-extra==0.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "wfo3fsVRdqJP",
        "outputId": "84c51f93-63ac-4a93-a78c-0c02709ce1ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\n",
            "shap 0.47.1 requires scikit-learn, which is not installed.\n",
            "sentence-transformers 3.4.1 requires scikit-learn, which is not installed.\n",
            "fastai 2.7.19 requires scikit-learn, which is not installed.\n",
            "librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n",
            "umap-learn 0.5.7 requires scikit-learn>=0.22, which is not installed.\n",
            "hdbscan 0.8.40 requires scikit-learn>=0.20, which is not installed.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "98ac8e0a4dfc4029aece3d06f1ad3c6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.2.2\n",
            "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-learn-extra==0.3.0\n",
            "  Using cached scikit_learn_extra-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import pairwise_distances_argmin_min"
      ],
      "metadata": {
        "id": "FR4Sv_QTbTnh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/4. DB_Fintechs (USD).xlsx\"\n",
        "df_base = pd.read_excel(url, sheet_name='Fintech Base')\n",
        "df_ext1 = pd.read_excel(url, sheet_name='Fintech Ext. 1')\n",
        "df_ext2 = pd.read_excel(url, sheet_name='Fintech Ext.2')\n",
        "df_ext3 = pd.read_excel(url, sheet_name='Fintech Ext.3')"
      ],
      "metadata": {
        "id": "gAjVrR0xb5KC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables = ['Edad', 'Ingresos', 'Egresos', 'Monto (EAD)']"
      ],
      "metadata": {
        "id": "HAAGeW-mcIS4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data_base_scaled = scaler.fit_transform(df_base[variables])"
      ],
      "metadata": {
        "id": "13ZoU7UTcKcd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "df_base['Cluster'] = kmeans.fit_predict(data_base_scaled)\n",
        "\n",
        "print(\"Clusters iniciales (K-Means):\", df_base['Cluster'].value_counts())\n",
        "print(\"Centroides iniciales (K-Means):\", kmeans.cluster_centers_)"
      ],
      "metadata": {
        "id": "eELyA2dwcMuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c746dd-772c-4c67-a803-ea2f33b07cc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x78ac6e9cae80>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: dlopen() error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters iniciales (K-Means): Cluster\n",
            "4    413\n",
            "1    383\n",
            "0    326\n",
            "2    223\n",
            "3    155\n",
            "Name: count, dtype: int64\n",
            "Centroides iniciales (K-Means): [[ 1.08010513 -0.74345247 -0.63965516 -0.65654682]\n",
            " [-0.67672847  0.33798192  0.33168035  0.2466104 ]\n",
            " [ 0.99129851  0.67162654  0.50979952  0.62240113]\n",
            " [-0.27921294  1.97623849  1.73058035  1.78919972]\n",
            " [-0.65546932 -0.83092314 -0.72743641 -0.71801192]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def integrar_y_clusterizar(df_base, df_new):\n",
        "    df_integrado = pd.concat([df_base, df_new], ignore_index=True)\n",
        "    datos_integrados_scaled = scaler.fit_transform(df_integrado[variables])\n",
        "    kmedoids = KMedoids(n_clusters=5, random_state=42)\n",
        "    df_integrado['Cluster'] = kmedoids.fit_predict(datos_integrados_scaled)\n",
        "    _, distances = pairwise_distances_argmin_min(kmedoids.cluster_centers_, datos_integrados_scaled)\n",
        "    sse = sum(distances**2)\n",
        "\n",
        "    cluster_counts = df_integrado['Cluster'].value_counts()\n",
        "    nuevos_clusters = df_integrado.iloc[-len(df_new):]['Cluster'].value_counts()\n",
        "\n",
        "    print(\"Clusters después de integración (K-Medoids):\", cluster_counts)\n",
        "    print(\"Medoids después de integración (K-Medoids):\", kmedoids.cluster_centers_)\n",
        "    print(\"Distribución de nuevos datos por cluster:\", nuevos_clusters)\n",
        "    print(\"Variabilidad de los clusters (SSE):\", sse)\n",
        "\n",
        "    return df_integrado"
      ],
      "metadata": {
        "id": "giK8iyxlebqT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIntegración con Ext. 1\")\n",
        "df_base = integrar_y_clusterizar(df_base, df_ext1)\n",
        "print(\"\\nIntegración con Ext. 2\")\n",
        "df_base = integrar_y_clusterizar(df_base, df_ext2)\n",
        "print(\"\\nIntegración con Ext. 3\")\n",
        "df_base = integrar_y_clusterizar(df_base, df_ext3)"
      ],
      "metadata": {
        "id": "LXIKc7UUejZp",
        "outputId": "f6ee478d-e48b-499e-bac2-d37a859b646f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Integración con Ext. 1\n",
            "Clusters después de integración (K-Medoids): Cluster\n",
            "3    772\n",
            "1    624\n",
            "4    619\n",
            "2    541\n",
            "0    445\n",
            "Name: count, dtype: int64\n",
            "Medoids después de integración (K-Medoids): [[ 1.22760437  0.29936466  0.26821535  0.33997077]\n",
            " [-0.23751423  1.25323287  0.84734789  1.20933371]\n",
            " [-0.88867805 -0.96016676 -0.77198442 -0.80812145]\n",
            " [-0.40030518 -0.15540548 -0.06626574 -0.17348599]\n",
            " [ 0.7392315  -0.93811295 -0.83872506 -0.78094923]]\n",
            "Distribución de nuevos datos por cluster: Cluster\n",
            "3    377\n",
            "4    306\n",
            "2    300\n",
            "1    294\n",
            "0    224\n",
            "Name: count, dtype: int64\n",
            "Variabilidad de los clusters (SSE): 0.0\n",
            "\n",
            "Integración con Ext. 2\n",
            "Clusters después de integración (K-Medoids): Cluster\n",
            "4    1069\n",
            "2    1048\n",
            "0     848\n",
            "1     789\n",
            "3     747\n",
            "Name: count, dtype: int64\n",
            "Medoids después de integración (K-Medoids): [[ 0.98369992  0.41744509  0.26362003  0.45276638]\n",
            " [-0.73104448  1.36990094  1.24415045  0.94722414]\n",
            " [-0.73104448 -0.15929416 -0.07100518 -0.11919824]\n",
            " [-0.89435347 -1.03097709 -0.87951957 -0.86548777]\n",
            " [ 0.73873643 -0.8236636  -0.68263499 -0.70145134]]\n",
            "Distribución de nuevos datos por cluster: Cluster\n",
            "2    354\n",
            "4    345\n",
            "0    299\n",
            "1    259\n",
            "3    243\n",
            "Name: count, dtype: int64\n",
            "Variabilidad de los clusters (SSE): 0.0\n",
            "\n",
            "Integración con Ext. 3\n",
            "Clusters después de integración (K-Medoids): Cluster\n",
            "3    1372\n",
            "4    1252\n",
            "1    1150\n",
            "0    1091\n",
            "2     978\n",
            "Name: count, dtype: int64\n",
            "Medoids después de integración (K-Medoids): [[ 0.97751607  0.22320448  0.25051771  0.26833565]\n",
            " [-0.33059607  1.37534234  1.02835295  1.0651345 ]\n",
            " [-0.82113813 -1.01160426 -0.87317173 -0.81446654]\n",
            " [-0.73938112 -0.16027337 -0.07067683 -0.12258382]\n",
            " [ 0.73224504 -0.92044113 -0.84359238 -0.78994386]]\n",
            "Distribución de nuevos datos por cluster: Cluster\n",
            "3    305\n",
            "4    297\n",
            "1    276\n",
            "0    245\n",
            "2    219\n",
            "Name: count, dtype: int64\n",
            "Variabilidad de los clusters (SSE): 4.440892098500627e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANALISIS DEL ARCHIVO**\n",
        "En el archivo se realiza un análisis de clustering de Fintechs en etapas, comenzando con un clustering inicial y luego integrando nuevos datos iterativamente. Se utilizan dos algoritmos, K-Means y K-Medoids, para la agrupación, y se evalúan los resultados en cada etapa para comprender cómo la incorporación de nuevos datos afecta la estructura de los clusters.\n",
        "\n",
        "El SSE se calcula después de cada integración de nuevos datos para ver cómo la variabilidad de los clusters se ve afectada por la incorporación de estos nuevos datos. Un aumento en el SSE después de una integración podría indicar que los nuevos datos no se ajustan bien a los clusters, mientras que un SSE que se mantiene estable podría indicar que los nuevos datos se integran bien a la estructura de los clusters."
      ],
      "metadata": {
        "id": "PpqhjOp9g5VB"
      }
    }
  ]
}